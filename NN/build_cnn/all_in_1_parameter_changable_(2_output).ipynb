{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1R8dLJJhGmQftMp4zXP5mu3kfE4w3Jzun","timestamp":1750171832443}],"collapsed_sections":["TiNr_gp1Hm1J","Y2pWhdELT8CR","d7405be4"],"toc_visible":true,"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Make things Ready"],"metadata":{"id":"iRIwCX4vlPl7"}},{"cell_type":"markdown","source":["## Mount google-drive & Load dataset"],"metadata":{"id":"TiNr_gp1Hm1J"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#shared path to drive\n","SHARED_PATH=\"/content/drive/MyDrive/Classroom/ChandernagoreCollegeSemVI-Addon 2025 Sem VI Computer Science Honours/ChandernagoreCollegeSemVI-Addon 2025 Sem VI Computer Science Honours\"\n","\n","#direct path to drive\n","DIRECT_PATH=\"/content/drive/MyDrive/Classroom/ChandernagoreCollegeSemVI-Addon 2025 Sem VI Computer Science Honours\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BMtWKi8SI_U7","executionInfo":{"status":"ok","timestamp":1750239361632,"user_tz":-330,"elapsed":2291,"user":{"displayName":"Shanku Bag","userId":"18150558297276386800"}},"outputId":"6d8829df-853a-4926-c542-30bc66bbe802"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","\n","# Determine the data path based on the existence of shared or direct paths\n","root_path = SHARED_PATH if os.path.exists(SHARED_PATH) else DIRECT_PATH if os.path.exists(DIRECT_PATH) else None\n","\n","DATA_PATH = ''\n","# Print the chosen path or an error message\n","if root_path:\n","    print(f\"Using path: {root_path}\")\n","    DATA_PATH = root_path + \"/Proj1_CGC_Building_with_sides_classify\"\n","    for filename in os.listdir(DATA_PATH):\n","        print(filename)\n","else:\n","    print(\"Neither shared nor direct path exists. Please check the paths.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xlRbiljJPAgi","executionInfo":{"status":"ok","timestamp":1750239361632,"user_tz":-330,"elapsed":6,"user":{"displayName":"Shanku Bag","userId":"18150558297276386800"}},"outputId":"4543232e-bca4-42e4-bd83-b52c406342dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using path: /content/drive/MyDrive/Classroom/ChandernagoreCollegeSemVI-Addon 2025 Sem VI Computer Science Honours/ChandernagoreCollegeSemVI-Addon 2025 Sem VI Computer Science Honours\n","validate_images\n","training_images\n","ALL_IMG_DATA\n","make_train-test-split_from_all_img_data.ipynb\n","ALL_IMG_DATA.csv\n","no_side_one_output_classify\n","expr3_RUN_THIS_all_in_one_changable(two output).ipynb\n","ResNet18(ptrain)_2-output_accy-74_(lr-0.0001_bs-16_ep-5_sd-2025).pth\n","expr2_resnet18_two_output_(sides classify).ipynb\n"]}]},{"cell_type":"markdown","source":["##  Setup Device & Random State"],"metadata":{"id":"Y2pWhdELT8CR"}},{"cell_type":"code","source":["import torch\n","import random\n","import numpy as np\n","\n","# Define device (CPU or GPU)\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(DEVICE)\n","\n","# define the random seed\n","SEED = 2025\n","\n","torch.manual_seed(SEED)\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(SEED)\n","    torch.cuda.manual_seed_all(SEED)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","os.environ['PYTHONHASHSEED'] = str(SEED)"],"metadata":{"id":"vnXDdqOGg7oH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750239363161,"user_tz":-330,"elapsed":1531,"user":{"displayName":"Shanku Bag","userId":"18150558297276386800"}},"outputId":"50b2ac13-f700-4bd3-9361-69f749085b80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"markdown","source":["## Load data(csv) & Train-Test Split"],"metadata":{"id":"LdN12-kmFRKV"}},{"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from IPython.display import display\n","\n","# Load the CSV data into a DataFrame\n","df = pd.read_csv(DATA_PATH+\"/ALL_IMG_DATA.csv\")\n","display(df.head())\n","#  --- Derive ALL unique categories from the FULL DataFrame ---\n","BUILDING_CATEGORIES = sorted(df['class'].unique().tolist())\n","FACADE_CATEGORIES = sorted(df['subclass'].unique().tolist())\n","\n","print(\"\\nMaster Building Categories:\", BUILDING_CATEGORIES)\n","print(\"Master Facade Categories:\", FACADE_CATEGORIES)"],"cell_type":"code","metadata":{"id":"Yi2oAd8iHiRR","colab":{"base_uri":"https://localhost:8080/","height":262},"executionInfo":{"status":"ok","timestamp":1750239364120,"user_tz":-330,"elapsed":956,"user":{"displayName":"Shanku Bag","userId":"18150558297276386800"}},"outputId":"5ec25faf-0886-4a8f-960d-26d263b9dec4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                               path    class subclass\n","0      /ALL_IMG_DATA/gurudeb_front/gurudeb_005.jpeg  gurudeb    front\n","1      /ALL_IMG_DATA/gurudeb_front/gurudeb_004.jpeg  gurudeb    front\n","2        /ALL_IMG_DATA/gurudeb_front/frame_0210.jpg  gurudeb    front\n","3      /ALL_IMG_DATA/gurudeb_front/gurudeb_002.jpeg  gurudeb    front\n","4  /ALL_IMG_DATA/gurudeb_front/gurufront_00040.jpeg  gurudeb    front"],"text/html":["\n","  <div id=\"df-a0d4776a-caa7-4ee5-b48b-c05cb67f6ae4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","      <th>class</th>\n","      <th>subclass</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/ALL_IMG_DATA/gurudeb_front/gurudeb_005.jpeg</td>\n","      <td>gurudeb</td>\n","      <td>front</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/ALL_IMG_DATA/gurudeb_front/gurudeb_004.jpeg</td>\n","      <td>gurudeb</td>\n","      <td>front</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/ALL_IMG_DATA/gurudeb_front/frame_0210.jpg</td>\n","      <td>gurudeb</td>\n","      <td>front</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/ALL_IMG_DATA/gurudeb_front/gurudeb_002.jpeg</td>\n","      <td>gurudeb</td>\n","      <td>front</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/ALL_IMG_DATA/gurudeb_front/gurufront_00040.jpeg</td>\n","      <td>gurudeb</td>\n","      <td>front</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0d4776a-caa7-4ee5-b48b-c05cb67f6ae4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a0d4776a-caa7-4ee5-b48b-c05cb67f6ae4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a0d4776a-caa7-4ee5-b48b-c05cb67f6ae4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-301b02e6-4210-4a8a-a1e3-1290f60558e2\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-301b02e6-4210-4a8a-a1e3-1290f60558e2')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-301b02e6-4210-4a8a-a1e3-1290f60558e2 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"print(\\\"Master Facade Categories:\\\", FACADE_CATEGORIES)\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/ALL_IMG_DATA/gurudeb_front/gurudeb_004.jpeg\",\n          \"/ALL_IMG_DATA/gurudeb_front/gurufront_00040.jpeg\",\n          \"/ALL_IMG_DATA/gurudeb_front/frame_0210.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"gurudeb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subclass\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"front\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Master Building Categories: ['admin', 'chemistry', 'gurudeb', 'heritage']\n","Master Facade Categories: ['front', 'left', 'right']\n"]}]},{"cell_type":"code","source":["# Split the data into training and testing sets\n","\n","\n","# train_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED)\n","# train_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED, stratify=df['class'])\n","train_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED, stratify=df['subclass'])\n","# this distrubutes better\n","print('------------ Training set subclass frequencies within each class ----------------')\n","print(train_df.groupby('class')['subclass'].value_counts().sort_index())\n","print('------------ Test set subclass frequencies within each class ----------------')\n","print(test_df.groupby('class')['subclass'].value_counts().sort_index())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HHcyEa8DHsbY","executionInfo":{"status":"ok","timestamp":1750239364147,"user_tz":-330,"elapsed":24,"user":{"displayName":"Shanku Bag","userId":"18150558297276386800"}},"outputId":"d0085f7f-d49b-4145-f299-96fd17cad1bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["------------ Training set subclass frequencies within each class ----------------\n","class      subclass\n","admin      front       57\n","           left        43\n","           right       56\n","chemistry  front       62\n","           left        57\n","           right       59\n","gurudeb    front       64\n","           left        41\n","           right       43\n","heritage   front       55\n","           left        51\n","Name: count, dtype: int64\n","------------ Test set subclass frequencies within each class ----------------\n","class      subclass\n","admin      front       11\n","           left         9\n","           right        8\n","chemistry  front       18\n","           left        13\n","           right       15\n","gurudeb    front       18\n","           left        13\n","           right       17\n","heritage   front       12\n","           left        13\n","Name: count, dtype: int64\n"]}]},{"cell_type":"markdown","source":["## Define data transformations"],"metadata":{"id":"frsQDDsBT0On"}},{"cell_type":"code","source":["import torchvision.transforms as transforms\n","\n","mean=[0.485, 0.456, 0.406]\n","standev=[0.229, 0.224, 0.225]\n","px=256\n","\n","train_transform = transforms.Compose([\n","    transforms.Resize((px, px)),\n","    transforms.RandomCrop((224, 224)),\n","    transforms.RandomRotation(10),\n","    # transforms.RandomVerticalFlip(),\n","    # transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(),\n","    transforms.RandomAffine(degrees=0),\n","    # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(mean), std=(standev))\n","])\n","\n","test_transform =  transforms.Compose([\n","    transforms.Resize((px, px)),\n","    transforms.CenterCrop((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(mean), std=(standev))\n","])\n","\n","print(train_transform)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sgGo5q0PS18n","executionInfo":{"status":"ok","timestamp":1750239365663,"user_tz":-330,"elapsed":1517,"user":{"displayName":"Shanku Bag","userId":"18150558297276386800"}},"outputId":"f33f0f2b-9776-492b-96ea-8c9c89e22780"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Compose(\n","    Resize(size=(256, 256), interpolation=bilinear, max_size=None, antialias=True)\n","    RandomCrop(size=(224, 224), padding=None)\n","    RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n","    ColorJitter(brightness=None, contrast=None, saturation=None, hue=None)\n","    RandomAffine(degrees=[0.0, 0.0])\n","    ToTensor()\n","    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",")\n"]}]},{"cell_type":"markdown","source":["## Load dataset with Torch"],"metadata":{"id":"cPAAYEi8WIkO"}},{"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","import torchvision.transforms as transforms\n","\n","class MakeTorchDataset(Dataset):\n","    def __init__(self, dataframe, image_base_path=DATA_PATH,\n","    building_categories=BUILDING_CATEGORIES, facade_categories=FACADE_CATEGORIES,\n","    transform=None):\n","        self.dataframe = dataframe\n","        self.image_base_path = image_base_path\n","        self.transform = transform\n","        # Create mappings for class and subclass based on the *provided* category lists\n","        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(building_categories)}\n","        self.subclass_to_idx = {sub_name: i for i, sub_name in enumerate(facade_categories)}\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        img_full_path = self.image_base_path+self.dataframe.iloc[idx]['path']\n","        # print(img_full_path)\n","        image = Image.open(img_full_path).convert('RGB')\n","\n","        # Access labels by column name for clarity and robustness\n","        building_class_name = self.dataframe.iloc[idx]['class']\n","        facade_subclass_name = self.dataframe.iloc[idx]['subclass']\n","\n","        # Convert string labels to integer indices using the pre-defined mappings\n","        building_class_label = self.class_to_idx[building_class_name]\n","        facade_subclass_label = self.subclass_to_idx[facade_subclass_name]\n","\n","        if self.transform: image = self.transform(image) # apply transformation\n","\n","        return image, building_class_label, facade_subclass_label"],"cell_type":"code","metadata":{"id":"-wFDN2p0oEnw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = MakeTorchDataset(dataframe=train_df, transform=train_transform)\n","test_dataset = MakeTorchDataset(dataframe=test_df, transform=test_transform)\n","\n","print(\"Building Categories:\", train_dataset.class_to_idx)\n","print(\"Facade Categories:\", train_dataset.subclass_to_idx)\n","\n","train_dataset.__getitem__(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P2HaNgCSuNo8","executionInfo":{"status":"ok","timestamp":1750239365710,"user_tz":-330,"elapsed":30,"user":{"displayName":"Shanku Bag","userId":"18150558297276386800"}},"outputId":"e71f3ca0-e171-4b71-cf77-46b3979eb8b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Building Categories: {'admin': 0, 'chemistry': 1, 'gurudeb': 2, 'heritage': 3}\n","Facade Categories: {'front': 0, 'left': 1, 'right': 2}\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","          ...,\n","          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n"," \n","         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","          ...,\n","          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n"," \n","         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","          ...,\n","          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]),\n"," 1,\n"," 1)"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["## Class definition"],"metadata":{"id":"RkvdZFDJK7_7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2RT56m8WP7t2"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","import numpy as np\n","from PIL import Image\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n","import matplotlib.pyplot as plt\n","\n","\n","class BuildingWithFacadeClassifier:\n","    \"\"\"\n","    A class for training, evaluating, and classifying images with a multi-head model\n","    using a custom dataset that directly provides two labels.\n","    \"\"\"\n","    def __init__(self, model, optimizer, batch_size=16,\n","    building_categories=BUILDING_CATEGORIES, facade_categories=FACADE_CATEGORIES,\n","    building_loss_fn=nn.CrossEntropyLoss(), facade_loss_fn=nn.CrossEntropyLoss(),\n","    train_dataset=train_dataset, test_dataset=test_dataset, device=DEVICE):\n","\n","        self.model = model.to(device)\n","        self.building_loss_fn = building_loss_fn\n","        self.facade_loss_fn = facade_loss_fn\n","        self.optimizer = optimizer\n","        self.batch_size = batch_size\n","        self.train_dataset = train_dataset\n","        self.test_dataset = test_dataset\n","        self.building_categories = building_categories\n","        self.facade_categories = facade_categories\n","        self.device = device\n","\n","        self.learning_rate = self.optimizer.param_groups[0]['lr']\n","        self.train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=2)\n","        self.test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2)\n","\n","\n","    ###############################################################################################\n","    # Train the model for a specified number of epochs...........................................\n","    def train(self, n_epochs=10, output_logging=True):\n","        # Store individual lists for plotting later if needed\n","        loss_graph_list, valid_loss_list = [], []\n","        building_accy_list, facade_accy_list = [], []\n","\n","        print(f\"Starting training with Learning Rate: {self.learning_rate}, Batch Size: {self.batch_size}, Epochs: {n_epochs}, Device: {self.device}----\")\n","\n","        for epoch in tqdm(range(n_epochs)):\n","            self.model.train() # set model to training mode each time\n","            training_loss = []\n","\n","            for i_image, i_building_label, i_facade_label in self.train_loader:\n","                i_image = i_image.to(self.device)\n","                i_building_label = i_building_label.to(self.device)\n","                i_facade_label = i_facade_label.to(self.device)\n","\n","                self.optimizer.zero_grad()\n","                output_building, output_facade = self.model(i_image)\n","\n","                # Calculate loss for each head\n","                loss_building = self.building_loss_fn(output_building, i_building_label)\n","                # Ensure retain_graph=True if building_loss_fn's backward pass needs to keep graph for facade_loss_fn's backward\n","                # loss_building.backward()\n","                loss_building.backward(retain_graph=True) # Need retain_graph=True\n","                # If they are independent, or if you sum before backward, it might not be needed.\n","                # A common pattern is to sum losses and then backward once.\n","\n","                loss_facade = self.facade_loss_fn(output_facade, i_facade_label)\n","                loss_facade.backward() # No retain_graph=True needed here\n","\n","                # Combine losses (e.g., simple average or weighted average)\n","                # Summing before backward is generally more efficient than two separate backward calls with retain_graph\n","                total_loss = (loss_building + loss_facade) / 2\n","                # total_loss.backward()\n","\n","                self.optimizer.step()\n","\n","                training_loss.append(total_loss.item()) # Use total_loss here\n","\n","            mean_training_loss = np.mean(training_loss)\n","            loss_graph_list.append(mean_training_loss)\n","\n","            # Call evaluate and get both accuracies and validation loss\n","            building_accy, facade_accy, current_valid_loss = self.evaluate(output_logging=False) # Set output_logging to False\n","\n","            valid_loss_list.append(current_valid_loss)\n","            building_accy_list.append(building_accy)\n","            facade_accy_list.append(facade_accy)\n","\n","            if output_logging:\n","                print(f\" Training loss: {mean_training_loss:.4f} --Validation Loss: {current_valid_loss:.4f} --Building Accuracy: {building_accy:.2f}% --Facade Accuracy: {facade_accy:.2f}%\")\n","\n","        print(\"Training done.....................\")\n","        # return detailed logs to plot them later\n","        return {\"train_loss\": loss_graph_list,\"val_loss\": valid_loss_list,\n","                \"building_accy\": building_accy_list,\"facade_accy\": facade_accy_list}\n","\n","\n","    ###############################################################################################\n","    # Evaluate the model on the test set (ENHANCED for both tasks)..............................\n","    def evaluate(self, output_logging=True, disp_confusion_matrix=False):\n","        self.model.eval() # set model to evaluation mode\n","        # Lists to store actual and predicted labels for confusion matrices\n","        actual_building_labels = []\n","        predicted_building_labels = []\n","        actual_facade_labels = []\n","        predicted_facade_labels = []\n","        validation_loss = []\n","\n","        with torch.no_grad():\n","            for i_image, i_building_label, i_facade_label in self.test_loader:\n","                i_image = i_image.to(self.device)\n","                i_building_label = i_building_label.to(self.device)\n","                i_facade_label = i_facade_label.to(self.device)\n","\n","                output_building, output_facade = self.model(i_image)\n","\n","                loss_building = self.building_loss_fn(output_building, i_building_label)\n","                loss_facade = self.facade_loss_fn(output_facade, i_facade_label)\n","                total_loss = (loss_building + loss_facade) / 2\n","                validation_loss.append(total_loss.item())\n","\n","                # Get predictions for building task\n","                _, predicted_building = torch.max(output_building.data, 1)\n","                actual_building_labels.extend(i_building_label.cpu().numpy())\n","                predicted_building_labels.extend(predicted_building.cpu().numpy())\n","\n","                # Get predictions for facade task\n","                _, predicted_facade = torch.max(output_facade.data, 1)\n","                actual_facade_labels.extend(i_facade_label.cpu().numpy())\n","                predicted_facade_labels.extend(predicted_facade.cpu().numpy())\n","\n","        # Calculate accuracies for each task\n","        building_accuracy = accuracy_score(actual_building_labels, predicted_building_labels)*100.0\n","        facade_accuracy = accuracy_score(actual_facade_labels, predicted_facade_labels)*100.0\n","\n","        average_validation_loss = np.mean(validation_loss)\n","\n","        if output_logging:\n","            print(f' --Validation Loss: {average_validation_loss:.4f}', end='')\n","            print(f'  --Building Accuracy: {building_accuracy:.2f}%', end='')\n","            print(f'  --Facade Accuracy: {facade_accuracy:.2f}%')\n","\n","        if disp_confusion_matrix:\n","            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5), dpi=80)\n","            # Confusion Matrix for Building Classification on the first subplot (ax1)\n","            ConfusionMatrixDisplay(\n","                confusion_matrix=confusion_matrix(actual_building_labels, predicted_building_labels),\n","                display_labels=[str(label) for label in self.building_categories] # Use defined building categories\n","            ).plot(cmap='Blues', ax=ax1) # Specify ax=ax1 to plot on the first subplot\n","            ax1.tick_params(axis='x', rotation=90) # Rotate x-axis labels for readability on ax1\n","            ax1.set_title(\"Building Classification\")\n","\n","            # Confusion Matrix for Facade Classification on the second subplot (ax2)\n","            ConfusionMatrixDisplay(\n","                confusion_matrix=confusion_matrix(actual_facade_labels, predicted_facade_labels),\n","                display_labels=[str(label) for label in self.facade_categories] # Use defined facade categories\n","            ).plot(cmap='Greens', ax=ax2) # Specify ax=ax2 to plot on the second subplot\n","            ax2.tick_params(axis='x', rotation=90) # Rotate x-axis labels for readability on ax2\n","            ax2.set_title(\"Facade Classification\")\n","\n","            plt.tight_layout() # Adjust layout to prevent overlap\n","            plt.show()\n","\n","        # Return both accuracies and the average loss\n","        return building_accuracy, facade_accuracy, average_validation_loss\n","\n","\n","    ###############################################################################################\n","    # Classify a single image (No changes needed here)....................................\n","    def classify_image(self, img_path, img_transform):\n","        self.model.eval()\n","\n","        try:\n","            image = Image.open(img_path).convert('RGB')\n","            plt.figure(dpi=50) # Set figure size\n","            plt.imshow(image) # Display the image\n","            plt.axis('off') # Turn off axis labels\n","            plt.show() # Show the plot\n","            image = img_transform(image).unsqueeze(0).to(self.device)\n","        except FileNotFoundError:\n","            print(f\"Error: Image not found at {img_path}\")\n","            return None, None, None, None\n","        except Exception as e:\n","            print(f\"Error processing image {img_path}: {e}\")\n","            return None, None, None, None\n","\n","        with torch.no_grad():\n","            output_building, output_facade = self.model(image)\n","\n","            probabilities1 = torch.softmax(output_building, dim=1)\n","            probabilities2 = torch.softmax(output_facade, dim=1)\n","\n","            print(\"Building Probabilities:\", probabilities1)\n","            print(\"Facade Probabilities:\", probabilities2)\n","\n","            _, predicted_building_index = torch.max(probabilities1, 1)\n","            _, predicted_facade_index = torch.max(probabilities2, 1)\n","\n","            predicted_building_class = self.building_categories[predicted_building_index.item()]\n","            predicted_facade_side = self.facade_categories[predicted_facade_index.item()]\n","\n","            print(f\"Predicted building class: {predicted_building_class} & the predicted facade side is: {predicted_facade_side}\")\n","\n","        return predicted_building_class, predicted_facade_side, probabilities1, probabilities2"]},{"cell_type":"code","source":["print(train_dataset.class_to_idx)\n","print(len(train_dataset.class_to_idx))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kbvr3Rf16EvB","outputId":"59380d97-7072-4273-f00f-6c173d1313b8","executionInfo":{"status":"ok","timestamp":1750239365782,"user_tz":-330,"elapsed":37,"user":{"displayName":"Shanku Bag","userId":"18150558297276386800"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'admin': 0, 'chemistry': 1, 'gurudeb': 2, 'heritage': 3}\n","4\n"]}]},{"cell_type":"markdown","metadata":{"id":"d7405be4"},"source":["## Plotting Training Results"]},{"cell_type":"code","metadata":{"id":"28e98627"},"source":["import matplotlib.pyplot as plt\n","\n","def ploting(ax, arr, color, lname, ylabel='loss', xlabel='epoch'):\n","    \"\"\"\n","    Plots data on a given axes.\n","\n","    Args:\n","        ax (matplotlib.axes.Axes): The axes to plot on.\n","        arr (list or numpy.ndarray): The data to plot.\n","        color (str): The color of the plot.\n","        lname (str): The label for the legend.\n","        ylabel (str, optional): The label for the y-axis. Defaults to 'loss'.\n","        xlabel (str, optional): The label for the x-axis. Defaults to 'epoch'.\n","    \"\"\"\n","    ax.plot(arr, color=color, label=lname)\n","    ax.scatter(range(len(arr)), arr, color=color, s=20) # Added marker size for better visibility\n","    ax.set_ylabel(ylabel, color=color)\n","    ax.tick_params(axis='y', labelcolor=color)\n","    ax.set_xlabel(xlabel)\n","\n","\n","def plot_classifier_results(results_dict, classifier_name): # <-- MODIFIED SIGNATURE\n","    \"\"\"\n","    Plots training loss, validation loss, and test accuracies for building and facade tasks.\n","    Args:\n","        results_dict (dict): A dictionary containing training results with keys:\n","                             'train_loss', 'val_loss', 'building_accy', 'facade_accy'.\n","        classifier_name (str): The name of the classifier for plot titles and labels.\n","    \"\"\"\n","    train_loss = results_dict['train_loss']\n","    valid_loss = results_dict['val_loss']\n","    building_accy = results_dict['building_accy']\n","    facade_accy = results_dict['facade_accy']\n","\n","    fig, ax1 = plt.subplots(figsize=(10, 5), dpi=90) # Increased figure size slightly for clarity\n","    ax2 = ax1.twinx() # Create a second y-axis that shares the same x-axis\n","\n","    # Plot Losses on ax1 (left y-axis)\n","    ploting(ax1, train_loss, color='red', lname=f'Training Loss', ylabel='Loss')\n","    ploting(ax1, valid_loss, color='purple', lname=f'Validation Loss', ylabel='Loss')\n","\n","    # Plot Accuracies on ax2 (right y-axis)\n","    ploting(ax2, building_accy, color='blue', lname=f'Building Accuracy(%)', ylabel='Accuracy(%)')\n","    ploting(ax2, facade_accy, color='green', lname=f'Facade Accuracy(%)', ylabel='Accuracy(%)') # New plot for facade accuracy\n","\n","    # Combine handles and labels from both axes for a single legend\n","    handles1, labels1 = ax1.get_legend_handles_labels()\n","    handles2, labels2 = ax2.get_legend_handles_labels()\n","    # Place legend outside the plot to avoid obscuring data\n","    # plt.legend(handles1 + handles2, labels1 + labels2, loc='center left', bbox_to_anchor=(1.05, 0.5))\n","    # Place legend inside at bottom left\n","    plt.legend(handles1 + handles2, labels1 + labels2, loc='lower left')\n","    plt.title(f'Training/Validation Loss and Accuracies per Epoch ({classifier_name})')\n","    plt.tight_layout() # Adjust layout to make space for the legend\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Modify the last layer for **Two Output** (building+facade)\n","\n","The `TwoOutputs` class is a custom PyTorch module designed to provide two distinct outputs from a single input. This is useful in scenarios where you want a model to perform two related but separate tasks simultaneously. In this case, it's used for classifying buildings and their facades/directions.\n","\n"],"metadata":{"id":"HV1pt9OORpVM"}},{"source":["import torch.nn as nn\n","\n","class TwoOutputs(nn.Module):\n","    \"\"\"\n","    A class contains Linear and ReLU modules to create two classification heads.\n","    The class provides two outputs:\n","    1. Building classification logits.\n","    2. Facade/direction classification logits.\n","    \"\"\"\n","    def __init__(self, in_feature, mid_feature, num_building_classes, num_facade_classes):\n","        super().__init__()\n","\n","        # Building Classification Head\n","        self.building_head = nn.Sequential(\n","            nn.Linear(in_features=in_feature, out_features=mid_feature),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.2),\n","            nn.Linear(in_features=mid_feature, out_features=num_building_classes) # Corrected output features\n","            # nn.Softmax(dim=1) # handels by CrossEntropyLoss()\n","        )\n","\n","        # Facade/Direction/Side Prediction Head\n","        self.facade_head = nn.Sequential(\n","            nn.Linear(in_features=in_feature, out_features=mid_feature),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.2),\n","            nn.Linear(in_features=mid_feature, out_features=num_facade_classes) # Corrected output features\n","            # nn.Softmax(dim=1) # handels by CrossEntropyLoss()\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Feed-forward function for the two classification heads.\n","        Args:\n","            x (torch.Tensor): Input tensor from the backbone's global average pooling layer.\n","        Returns:\n","            tuple: (building_logits, facade_logits)\n","        \"\"\"\n","        building_logits = self.building_head(x)\n","        facade_logits = self.facade_head(x)\n","\n","        return building_logits, facade_logits"],"cell_type":"code","metadata":{"id":"S-M9kSJfv2BS"},"execution_count":null,"outputs":[]},{"source":["def modify_last_layer(model, pretrained=False,\n","categories1=BUILDING_CATEGORIES, categories2=FACADE_CATEGORIES):\n","    model._is_pretrained_backbone = pretrained\n","    # Assuming the last layer is named 'fc' as in many torchvision models\n","    last_layer_in = model.fc.in_features\n","    no_classes = len(categories1)\n","    no_subclasses = len(categories2)\n","    new_mid_layer_out = 256 # You can adjust this based on your needs\n","    print(f\"last layer output for model = {last_layer_in} -> {new_mid_layer_out} -> convert to {no_classes} and {no_subclasses} outputs\")\n","\n","    # Replace the last layer with your custom TwoOutputs module\n","    model.fc = TwoOutputs(last_layer_in, new_mid_layer_out, no_classes, no_subclasses)\n","    if pretrained:\n","        model = fc_weight_bias_init(model)\n","    else:\n","        model = all_weight_bias_init(model)\n","\n","    return model"],"cell_type":"code","metadata":{"id":"CsdoohCWLUtC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn.init as init\n","def fc_weight_bias_init(model):\n","    for module in model.fc.modules():\n","        if isinstance(module, nn.Linear):\n","            init.kaiming_normal_(\n","                module.weight, a=0, mode='fan_out', nonlinearity='relu',\n","            )\n","            if module.bias is not None:\n","                fan_in, fan_out = init._calculate_fan_in_and_fan_out(module.weight)\n","                bound = 1 / (fan_out)**0.5\n","                init.normal_(module.bias, -bound, bound)\n","    return model\n","\n","def all_weight_bias_init(model):\n","    for module in model.modules():\n","        if isinstance(module, nn.Linear):\n","            init.kaiming_normal_(\n","                module.weight, a=0, mode='fan_out', nonlinearity='relu',\n","            )\n","            if module.bias is not None:\n","                fan_in, fan_out = init._calculate_fan_in_and_fan_out(module.weight)\n","                bound = 1 / (fan_out)**0.5\n","                init.normal_(module.bias, -bound, bound)\n","    return model"],"metadata":{"id":"UeHD-EimOf1B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Resets the weights of the entire model instance using the custom init_weights function.\n","def reset_model(model):\n","    if model._is_pretrained_backbone:\n","        model.apply(fc_weight_bias_init)\n","        print('reset last')\n","    else:\n","        model.apply(all_weight_bias_init)\n","        print('reset all')"],"metadata":{"id":"0Ymprs4x9_O5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Main part (Create Instances & Calssify)\n"],"metadata":{"id":"UOQhfCUMlVh5"}},{"cell_type":"code","source":["import torchvision.models as models\n","from torch import optim"],"metadata":{"id":"D_X_rxMP-8Cx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model 1 ResNet18 non pretrained"],"metadata":{"id":"Yo6ltXLUYTWg"}},{"cell_type":"code","source":["# test model 1\n","model1 = models.resnet18(weights=None)\n","model1 = modify_last_layer(model1, pretrained=False)\n","model1._is_pretrained_backbone\n"],"metadata":{"id":"MNfTNsHIRJcs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750239366011,"user_tz":-330,"elapsed":189,"user":{"displayName":"Shanku Bag","userId":"18150558297276386800"}},"outputId":"4e9d90cc-b747-4e51-d372-76da9ac8b251"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["last layer output for model = 512 -> 256 -> convert to 4 and 3 outputs\n"]},{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["#### Classifier 1"],"metadata":{"id":"3LntBa3GRPO8"}},{"cell_type":"code","source":["# Instance 1 with parameters\n","\n","classifier1 = BuildingWithFacadeClassifier(\n","    model=model1,\n","    optimizer=optim.Adam(model1.parameters(), lr=0.001),\n","    batch_size=16,\n",")\n","\n","# change output_logging=True to print output of each iteration\n","# result1 = classifier1.train(n_epochs=15, output_logging=False)\n","result1 = classifier1.train(n_epochs=15, output_logging=True)"],"metadata":{"id":"zuMjQgmpQ1p2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot results\n","plot_classifier_results(result1, 'Classifier 1 (ResNet18)')\n","classifier1.evaluate(output_logging=True, disp_confusion_matrix=True)"],"metadata":{"id":"k5IjdDtmI2L1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Classifier 2"],"metadata":{"id":"mTHkkKzXRSvr"}},{"cell_type":"code","source":["# Instance 2 with different parameters\n","reset_model(model1) # NEEDED to clear previous run data\n","classifier2 = BuildingWithFacadeClassifier(\n","    model=model1,\n","    optimizer=optim.Adam(model1.parameters(), lr=0.0001),\n","    batch_size=32,\n",")\n","\n","# change output_logging=True to print output of each iteration\n","# result2 = classifier2.train(n_epochs=10, output_logging=False)\n","result2 = classifier2.train(n_epochs=10, output_logging=True)"],"metadata":{"id":"dT5M2GaMMrhU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot results\n","plot_classifier_results(result2, 'Classifier 2 (ResNet18)')\n","classifier2.evaluate(output_logging=True, disp_confusion_matrix=True)"],"metadata":{"id":"7wMaRrs2I7qd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Classifier 3"],"metadata":{"id":"HDDqIbEXZ9w1"}},{"cell_type":"markdown","source":["### model 2 ResNet Pretrained=True"],"metadata":{"id":"dAmlwzv0c05R"}},{"cell_type":"code","source":["model2 = models.resnet18(weights ='ResNet18_Weights.DEFAULT')  # pretrained = True\n","# Freeze all parameters in the feature extraction layers\n","\n","# for param in model2.parameters():\n","#     param.requires_grad = False\n","model2 = modify_last_layer(model2, pretrained=True)\n","model2._is_pretrained_backbone\n"],"metadata":{"id":"A9ygsWfhc505"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Classifier 4"],"metadata":{"id":"nRbrE1BligSq"}},{"cell_type":"code","source":["# model 2 -> Instance 1 with different parameters\n","\n","classifier4 = BuildingWithFacadeClassifier(\n","    model=model2,\n","    optimizer=optim.Adam(model1.parameters(), lr=0.0001),\n","    batch_size=16\n",")\n","\n","# change output_logging=True to print output of each iteration\n","# result4 = classifier4.train(n_epochs=20, output_logging=False)\n","result4 = classifier4.train(n_epochs=20, output_logging=True)\n","\n"],"metadata":{"id":"ytYHnJEbc45_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot results\n","plot_classifier_results(result4, 'Classifier 4 (ResNet18 Pretrained)')\n","classifier4.evaluate(output_logging=True, disp_confusion_matrix=True)"],"metadata":{"id":"4vDGzwD_JFBW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Classifier 5"],"metadata":{"id":"0zMN2Wq8xY50"}},{"cell_type":"code","source":["# model 2 -> Instance 2 with different parameters\n","reset_model(model2) # NEEDED for clearing previous run data\n","classifier5 = BuildingWithFacadeClassifier(\n","    model=model2,\n","    optimizer=optim.Adam(model1.parameters(), lr=0.0001),\n","    batch_size=16\n",")\n","\n","# change output_logging=True to print output of each iteration\n","# result4 = classifier4.train(n_epochs=20, output_logging=False)\n","result5 = classifier5.train(n_epochs=5, output_logging=True)\n","\n"],"metadata":{"id":"lRqkqO4dwAQp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot results\n","plot_classifier_results(result5, 'Classifier 5 (ResNet18 Pretrained)')\n","classifier5.evaluate(output_logging=True, disp_confusion_matrix=True)\n"],"metadata":{"id":"AdM4n7M7yU0C"},"execution_count":null,"outputs":[]}]}